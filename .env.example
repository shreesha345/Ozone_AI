# Misinformation Detection Agent - Environment Configuration

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================
# Specify which LLM model to use. The system will auto-detect the provider.
# 
# If MODEL is not set, the system will automatically select based on available API keys:
# 1. Anthropic (if ANTHROPIC_API_KEY is set)
# 2. OpenAI (if OPENAI_API_KEY is set)
# 3. Google (if GOOGLE_API_KEY is set)
# 4. Ollama/Gemma3 (free, local - no API key needed)
#
# Examples:
# - OpenAI: gpt-4o, gpt-4-turbo, gpt-3.5-turbo, o1-preview, o1-mini
# - Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229, claude-sonnet-4-5-20250929
# - Google: gemini-pro, gemini-1.5-pro, gemini-1.5-flash
# - Ollama: gemma3:latest, llama3, mistral, qwen2.5, etc.

# Leave blank for auto-detection, or specify a model:
# MODEL=claude-sonnet-4-5-20250929
# MODEL=gpt-4o
# MODEL=gemma3:latest

MODEL_TEMPERATURE=0

# Ollama Base URL (only needed if using Ollama models)
OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================
# Maximum number of claims to fact-check in parallel
# Higher values = faster analysis but more API calls simultaneously
# Lower values = slower but more controlled API usage
# 
# Recommended values:
# - 1-2: Conservative (avoid rate limits, lower cost)
# - 3-5: Balanced (default, good for most use cases)
# - 5-10: Aggressive (fast but may hit rate limits)

MAX_PARALLEL_CLAIMS=3

# Maximum number of claims to extract and verify
# Limits total API calls to avoid rate limits and reduce costs
# Recommended: 3-7 claims for most analyses

MAX_CLAIMS_TO_CHECK=5

# =============================================================================
# API KEYS
# =============================================================================
# Provide the API key for your chosen model provider

# Anthropic (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Google (for Gemini models)
GOOGLE_API_KEY=your_google_api_key_here

# Ollama (for local models - no API key needed)
# Just ensure Ollama is running locally on port 11434
# Install: https://ollama.ai
# Pull model: ollama pull gemma3:latest

# Perplexity (for web search - required for fact-checking)
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# =============================================================================
# NEO4J CONFIGURATION (Optional - for graph storage)
# =============================================================================
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password_here
NEO4J_DATABASE=neo4j

# =============================================================================
# USAGE EXAMPLES
# =============================================================================

# Example 1: Using OpenAI GPT-4o
# MODEL=gpt-4o
# OPENAI_API_KEY=sk-...
# PERPLEXITY_API_KEY=pplx-...

# Example 2: Using Anthropic Claude
# MODEL=claude-3-5-sonnet-20241022
# ANTHROPIC_API_KEY=sk-ant-...
# PERPLEXITY_API_KEY=pplx-...

# Example 3: Using Google Gemini
# MODEL=gemini-1.5-pro
# GOOGLE_API_KEY=AIza...
# PERPLEXITY_API_KEY=pplx-...

# Example 4: Using Ollama (Local - Free)
# MODEL=gemma3:latest
# OLLAMA_BASE_URL=http://localhost:11434
# PERPLEXITY_API_KEY=pplx-...

# =============================================================================
# NOTES
# =============================================================================
# - Only the API key for your chosen model provider is required
# - PERPLEXITY_API_KEY is required for web search functionality
# - Neo4j configuration is optional (for storing analysis in graph database)
# - Temperature controls randomness (0 = deterministic, 1 = creative)
